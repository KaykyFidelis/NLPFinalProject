{"cells":[{"cell_type":"markdown","id":"854f4f61","metadata":{"id":"854f4f61"},"source":["\n","# KuBertNetes - Projeto de PLN\n","\n","**Nome: Kayky Fidelis Serafim**\n","\n","**Email: kayky.fidelis.serafim@ccc.ufcg.edu.br**\n","\n","**Matrícula: 122110481**\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"A_euu12KWtbA"},"id":"A_euu12KWtbA"},{"cell_type":"markdown","id":"70c0c145","metadata":{"id":"70c0c145"},"source":["## 1) Environment setup"]},{"cell_type":"markdown","source":["## Instalação das bibliotecas necessárias"],"metadata":{"id":"5MG51FPYV6_u"},"id":"5MG51FPYV6_u"},{"cell_type":"code","execution_count":null,"id":"2b802849","metadata":{"id":"2b802849"},"outputs":[],"source":["!pip -q install scikit-learn==1.5.2 transformers==4.44.2 pypdf==4.3.1 unidecode==1.3.8\n","\n","from pathlib import Path\n","\n","import re, unicodedata\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","import torch\n","\n"]},{"cell_type":"markdown","source":["## Scraping dos Dados na documentação do K8S\n","\n","O código abaixo coleta recursivamente dados da documentação do kubernetes, essa coleta é salva e um arquivo que é crucial para a execução deste projeto, no entanto, leva um tempo para ser realizada."],"metadata":{"id":"5cHJgOraTtd1"},"id":"5cHJgOraTtd1"},{"cell_type":"code","source":["!pip -q install beautifulsoup4\n","\n","OUT_DIR = \"/content/\"\n","SEEDS = [\n","    \"https://kubernetes.io/docs/home/\",\n","    \"https://kubernetes.io/docs/concepts/\",\n","    \"https://kubernetes.io/docs/reference/glossary/\",\n","]\n","MAX_PAGES = 600\n","SLEEP_SEC = 0.8\n","MAX_CHUNK_WORDS = 220\n","CHUNK_OVERLAP = 80\n","\n","import time, re, hashlib\n","from urllib.parse import urljoin, urlparse, urldefrag\n","import requests\n","from bs4 import BeautifulSoup\n","from urllib import robotparser\n","from collections import deque\n","from pathlib import Path\n","\n","ALLOWED_DOMAINS = {\n","    \"kubernetes.io\",\n","    \"kubernetes.io:443\",\n","}\n","\n","ALLOWED_PATH_PREFIXES = (\n","    \"/docs/\",\n","    \"/blog/\",\n","    \"/reference/\",\n","    \"/es/docs/\",\n","    \"/en/docs/\",\n",")\n","\n","HEADERS = {\"User-Agent\": \"k8s-corpus-crawler/0.1 (+research/edu)\"}\n","\n","def can_fetch(rp, url):\n","    try:\n","        return rp.can_fetch(HEADERS[\"User-Agent\"], url)\n","    except Exception:\n","        return True\n","\n","def normalize_url(base, href):\n","    if not href:\n","        return None\n","    href = urljoin(base, href)\n","    href, _frag = urldefrag(href)\n","    parsed = urlparse(href)\n","    if parsed.scheme not in (\"http\",\"https\"):\n","        return None\n","    host = parsed.netloc.lower()\n","    if host not in ALLOWED_DOMAINS:\n","        return None\n","    if not any(parsed.path.startswith(p) for p in ALLOWED_PATH_PREFIXES):\n","        return None\n","    return href\n","\n","def fetch(url, session, rp, timeout=15):\n","    if not can_fetch(rp, url):\n","        return None, None\n","    try:\n","        r = session.get(url, headers=HEADERS, timeout=timeout)\n","        ctype = r.headers.get(\"Content-Type\",\"\").lower()\n","        if r.status_code != 200 or (\"text/html\" not in ctype):\n","            return None, None\n","        return r.text, r.url\n","    except requests.RequestException:\n","        return None, None\n","\n","def html_to_text(html):\n","    soup = BeautifulSoup(html, \"html.parser\")\n","    for tag in soup([\"script\",\"style\",\"noscript\",\"header\",\"footer\",\"nav\",\"aside\"]):\n","        tag.decompose()\n","\n","    for pre in soup.find_all(\"pre\"):\n","        pre.insert_before(\"\\n```code\\n\")\n","        pre.insert_after(\"\\n```\\n\")\n","\n","    for i in range(1,7):\n","        for h in soup.find_all(f\"h{i}\"):\n","            h.insert_before(\"\\n\" + \"#\"*i + \" \" + (h.get_text(\" \", strip=True) or \"\") + \"\\n\")\n","    text = soup.get_text(\"\\n\", strip=True)\n","    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n","    return text.strip()\n","\n","def chunk_text(txt, max_words=220, overlap=80):\n","    words = txt.split()\n","    chunks = []\n","    i = 0\n","    while i < len(words):\n","        chunk = words[i:i+max_words]\n","        if not chunk:\n","            break\n","        chunks.append(\" \".join(chunk))\n","        i += max_words - overlap\n","    return chunks\n","\n","out = Path(OUT_DIR); out.mkdir(parents=True, exist_ok=True)\n","pages_dir = out / \"pages\"; pages_dir.mkdir(exist_ok=True)\n","chunks_dir = out / \"chunks\"; chunks_dir.mkdir(exist_ok=True)\n","\n","session = requests.Session()\n","\n","parsed_seed = urlparse(SEEDS[0])\n","robots_url = f\"{parsed_seed.scheme}://{parsed_seed.netloc}/robots.txt\"\n","rp = robotparser.RobotFileParser()\n","try:\n","    rp.set_url(robots_url); rp.read()\n","except Exception:\n","    pass\n","\n","seen = set()\n","q = deque(SEEDS)\n","visited = 0\n","all_chunks = []\n","\n","print(f\"Começando crawl… (MAX_PAGES={MAX_PAGES})\")\n","start_time = time.time()\n","\n","while q and visited < MAX_PAGES:\n","    url = q.popleft()\n","    if url in seen:\n","        continue\n","    seen.add(url)\n","\n","    html, final_url = fetch(url, session, rp)\n","    time.sleep(SLEEP_SEC)\n","    if not html:\n","        continue\n","\n","    visited += 1\n","    text = html_to_text(html)\n","\n","    uid = hashlib.md5((final_url or url).encode(\"utf-8\")).hexdigest()[:10]\n","    page_path = pages_dir / f\"{uid}.txt\"\n","    page_path.write_text(f\"URL: {final_url or url}\\n\\n{text}\\n\", encoding=\"utf-8\")\n","\n","    soup = BeautifulSoup(html, \"html.parser\")\n","    for a in soup.find_all(\"a\"):\n","        nurl = normalize_url(final_url or url, a.get(\"href\"))\n","        if nurl and nurl not in seen:\n","            q.append(nurl)\n","\n","    for j, ch in enumerate(chunk_text(text, max_words=MAX_CHUNK_WORDS, overlap=CHUNK_OVERLAP)):\n","        (chunks_dir / f\"{uid}_{j:03d}.txt\").write_text(ch, encoding=\"utf-8\")\n","        all_chunks.append(ch)\n","\n","    if visited % 25 == 0:\n","        elapsed = time.time() - start_time\n","        print(f\"[{visited} páginas]  fila={len(q)}  tempo={elapsed:.1f}s\")\n","\n","corpus = out / \"k8s_corpus_scraped.txt\"\n","corpus.write_text(\"\\n\\n=== DOC CHUNK ===\\n\\n\".join(all_chunks), encoding=\"utf-8\")\n","\n","elapsed = time.time() - start_time\n","print(f\"\\nConcluído ✅  Visited: {visited} páginas  |  Chunks: {len(all_chunks)}\")\n","print(f\"Corpus: {corpus}\")\n","print(f\"Tempo total: {elapsed:.1f}s\")\n","\n","print(\"\\nExemplo de arquivos:\")\n","!ls -lah \"$OUT_DIR\" | head -n 20\n","!ls -lah \"$OUT_DIR/chunks\" | head -n 20\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnYPieIgUeV3","executionInfo":{"status":"ok","timestamp":1758315420903,"user_tz":-120,"elapsed":873039,"user":{"displayName":"KAYKY FIDELIS SERAFIM","userId":"03357177986102336329"}},"outputId":"91c69556-9968-4c42-82a4-ad93c6790f46"},"id":"CnYPieIgUeV3","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Começando crawl… (MAX_PAGES=600)\n","[25 páginas]  fila=20411  tempo=40.6s\n","[50 páginas]  fila=39851  tempo=75.3s\n","[75 páginas]  fila=58744  tempo=111.8s\n","[100 páginas]  fila=76953  tempo=148.7s\n","[125 páginas]  fila=94456  tempo=183.5s\n","[150 páginas]  fila=111366  tempo=219.3s\n","[175 páginas]  fila=127542  tempo=254.5s\n","[200 páginas]  fila=143180  tempo=289.4s\n","[225 páginas]  fila=158038  tempo=324.5s\n","[250 páginas]  fila=172252  tempo=359.5s\n","[275 páginas]  fila=185837  tempo=395.4s\n","[300 páginas]  fila=198822  tempo=431.1s\n","[325 páginas]  fila=211172  tempo=467.0s\n","[350 páginas]  fila=222894  tempo=502.7s\n","[375 páginas]  fila=233970  tempo=539.1s\n","[400 páginas]  fila=244430  tempo=574.3s\n","[425 páginas]  fila=254244  tempo=610.2s\n","[450 páginas]  fila=263534  tempo=647.5s\n","[475 páginas]  fila=273061  tempo=685.5s\n","[500 páginas]  fila=282524  tempo=721.7s\n","[525 páginas]  fila=290846  tempo=757.3s\n","[550 páginas]  fila=298546  tempo=793.1s\n","[575 páginas]  fila=304598  tempo=828.9s\n","[600 páginas]  fila=310045  tempo=863.8s\n","\n","Concluído ✅  Visited: 600 páginas  |  Chunks: 7283\n","Corpus: /content/k8s_corpus_scraped.txt\n","Tempo total: 863.9s\n","\n","Exemplo de arquivos:\n","total 11M\n","drwxr-xr-x 1 root root 4.0K Sep 19 18:57 .\n","drwxr-xr-x 1 root root 4.0K Sep 19 18:30 ..\n","drwxr-xr-x 2 root root 264K Sep 19 19:28 chunks\n","drwxr-xr-x 4 root root 4.0K Sep 16 13:40 .config\n","-rw-r--r-- 1 root root 9.9M Sep 19 20:57 k8s_corpus_scraped.txt\n","drwxr-xr-x 2 root root  20K Sep 19 19:28 pages\n","drwxr-xr-x 1 root root 4.0K Sep 16 13:40 sample_data\n","total 29M\n","drwxr-xr-x 2 root root 264K Sep 19 19:28 .\n","drwxr-xr-x 1 root root 4.0K Sep 19 18:57 ..\n","-rw-r--r-- 1 root root 1.4K Sep 19 20:50 010c7593c5_000.txt\n","-rw-r--r-- 1 root root 1.8K Sep 19 20:50 010c7593c5_001.txt\n","-rw-r--r-- 1 root root 1.7K Sep 19 20:50 010c7593c5_002.txt\n","-rw-r--r-- 1 root root 1.2K Sep 19 20:50 010c7593c5_003.txt\n","-rw-r--r-- 1 root root  262 Sep 19 20:50 010c7593c5_004.txt\n","-rw-r--r-- 1 root root 2.0K Sep 19 20:55 0165818318_000.txt\n","-rw-r--r-- 1 root root 1.6K Sep 19 20:55 0165818318_001.txt\n","-rw-r--r-- 1 root root 1.7K Sep 19 20:55 0165818318_002.txt\n","-rw-r--r-- 1 root root 1.6K Sep 19 20:55 0165818318_003.txt\n","-rw-r--r-- 1 root root 1.6K Sep 19 20:55 0165818318_004.txt\n","-rw-r--r-- 1 root root 1.5K Sep 19 20:55 0165818318_005.txt\n","-rw-r--r-- 1 root root 1.6K Sep 19 20:55 0165818318_006.txt\n","-rw-r--r-- 1 root root 1.5K Sep 19 20:55 0165818318_007.txt\n","-rw-r--r-- 1 root root 1.7K Sep 19 20:55 0165818318_008.txt\n","-rw-r--r-- 1 root root 1.7K Sep 19 20:55 0165818318_009.txt\n","-rw-r--r-- 1 root root  968 Sep 19 20:55 0165818318_010.txt\n","-rw-r--r-- 1 root root  100 Sep 19 20:55 0165818318_011.txt\n"]}]},{"cell_type":"markdown","id":"6c6165c0","metadata":{"id":"6c6165c0"},"source":["\n","## 2) Verificação da Coleta"]},{"cell_type":"code","execution_count":null,"id":"c68f2051","metadata":{"id":"c68f2051","executionInfo":{"status":"ok","timestamp":1758310289737,"user_tz":-120,"elapsed":14,"user":{"displayName":"KAYKY FIDELIS SERAFIM","userId":"03357177986102336329"}},"outputId":"5492cc47-4e3c-45fa-a11a-57dcb1c9d000","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Exists: True \n","Path: /content/k8s_corpus_scraped.txt\n"]}],"source":["\n","CORPUS_PATH = \"/content/k8s_corpus_scraped.txt\"\n","p = Path(CORPUS_PATH)\n","print(\"Exists:\", p.exists(), \"\\nPath:\", p)\n"]},{"cell_type":"markdown","id":"3e03812b","metadata":{"id":"3e03812b"},"source":["## 3) Normalização do Corpus utilizando regex"]},{"cell_type":"code","execution_count":null,"id":"831dd0cb","metadata":{"id":"831dd0cb","executionInfo":{"status":"ok","timestamp":1758310295845,"user_tz":-120,"elapsed":4509,"user":{"displayName":"KAYKY FIDELIS SERAFIM","userId":"03357177986102336329"}},"outputId":"bdd05921-c90e-44ae-c55b-e16ab9adb1b1","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Characters: 10299347\n","Kubernetes Documentation | Kubernetes Kubernetes is an open source container orchestration engine for automating deployment, scaling, and management of containerized applications. The open source project is hosted by the Cloud Native Computing Foundation ( CNCF ). ## Understand Kubernetes Understand Kubernetes Learn about Kubernetes and its fundamental concepts. Why Kubernetes? Components of a cluster The Kubernetes API Objects In Kubernetes Containers Workloads and Pods View Concepts ## Try Kubernetes Try Kubernetes Follow tutorials to learn how to deploy applications in Kubernetes. Hello Minikube Walkthrough the basics Stateless Example: PHP Guestbook with Redis Stateful Example: Wordpress with Persistent Volumes View Tutorials ## Set up a K8s cluster Set up a K8s cluster Get Kubernetes running based on your resources and needs. Learning environment Production environment Install the kubeadm setup tool Securing a cluster kubeadm command reference Set up Kubernetes ## Learn how to use Kubernetes Learn how to use Kubernetes Look up common tasks and how to perform them using a short sequence of steps. kubectl Quick Reference Install kubectl Configure access to clusters Use the Web U\n"]}],"source":["def normalize_text(t: str) -> str:\n","    t = unicodedata.normalize(\"NFKC\", t)\n","    t = t.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n","    t = re.sub(r\"[ \\t\\u00A0]+\", \" \", t)\n","    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t).strip()\n","    return t\n","\n","raw = Path(CORPUS_PATH).read_text(encoding=\"utf-8\", errors=\"ignore\")\n","text = normalize_text(raw)\n","print(\"Characters:\", len(text))\n","print(text[:1200])\n"]},{"cell_type":"markdown","id":"ce933679","metadata":{"id":"ce933679"},"source":["## 4) Criação dos Chunks com sobreposição"]},{"cell_type":"code","execution_count":null,"id":"47617e14","metadata":{"id":"47617e14","executionInfo":{"status":"ok","timestamp":1758310296766,"user_tz":-120,"elapsed":919,"user":{"displayName":"KAYKY FIDELIS SERAFIM","userId":"03357177986102336329"}},"outputId":"2be7cd92-62d4-4cac-8964-882795d7b7eb","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Total chunks: 5965\n","Sample chunk:\n"," Kubernetes Documentation | Kubernetes Kubernetes is an open source container orchestration engine for automating deployment, scaling, and management of containerized applications. The open source project is hosted by the Cloud Native Computing Foundation ( CNCF ). ## Understand Kubernetes Understand Kubernetes Learn about Kubernetes and its fundamental concepts. Why Kubernetes? Components of a cluster The Kubernetes API Objects In Kubernetes Containers Workloads and Pods View Concepts ## Try Kubernetes Try Kubernetes Follow tutorials to learn how to deploy applications in Kubernetes. Hello Min\n"]}],"source":["def chunk_text(text: str, max_words=320, overlap=64):\n","    words = text.split()\n","    chunks = []\n","    i = 0\n","    while i < len(words):\n","        j = min(i + max_words, len(words))\n","        chunk = \" \".join(words[i:j])\n","        chunks.append(chunk)\n","        i = j - overlap if j - overlap > i else j\n","    return chunks\n","\n","chunks = chunk_text(text, max_words=320, overlap=64)\n","print(\"Total chunks:\", len(chunks))\n","print(\"Sample chunk:\\n\", chunks[0][:600])\n"]},{"cell_type":"markdown","id":"ef204db3","metadata":{"id":"ef204db3"},"source":["## 5) Criação do TF‑IDF (n-grams)"]},{"cell_type":"code","execution_count":null,"id":"dd70acec","metadata":{"id":"dd70acec","executionInfo":{"status":"ok","timestamp":1758310324212,"user_tz":-120,"elapsed":27444,"user":{"displayName":"KAYKY FIDELIS SERAFIM","userId":"03357177986102336329"}},"outputId":"35f097fb-0433-4d06-8def-8c9559f88553","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix shape: (5965, 268219)\n"]}],"source":["vectorizer = TfidfVectorizer(\n","    lowercase=False,\n","    analyzer=\"char_wb\",\n","    ngram_range=(3,5),\n","    min_df=1\n",")\n","X = vectorizer.fit_transform(chunks)\n","\n","def tfidf_search(query, top_k=8):\n","    qv = vectorizer.transform([query])\n","    sims = cosine_similarity(qv, X)[0]\n","    idx = sims.argsort()[::-1][:top_k]\n","    return [(chunks[i], float(sims[i]), i) for i in idx]\n","\n","print(\"Matrix shape:\", X.shape)\n"]},{"cell_type":"markdown","id":"ea870817","metadata":{"id":"ea870817"},"source":["## 6) Carregamento do Bert para Pergunta e Resposta (QA) - Sem Treino"]},{"cell_type":"code","execution_count":null,"id":"d19b1be4","metadata":{"id":"d19b1be4","executionInfo":{"status":"ok","timestamp":1758311680274,"user_tz":-120,"elapsed":577,"user":{"displayName":"KAYKY FIDELIS SERAFIM","userId":"03357177986102336329"}},"outputId":"caedbb62-72fc-4780-a95a-b48a1bbcd595","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["qa_name = \"deepset/bert-base-cased-squad2\"\n","qa_tok = AutoTokenizer.from_pretrained(qa_name)\n","qa_model = AutoModelForQuestionAnswering.from_pretrained(qa_name)\n","\n","def extract_answer(question: str, context: str):\n","    inputs = qa_tok(question, context, return_tensors=\"pt\", truncation=True, max_length=512)\n","    with torch.no_grad():\n","        out = qa_model(**inputs)\n","    start = int(torch.argmax(out.start_logits))\n","    end = int(torch.argmax(out.end_logits))\n","    if end < start:\n","        return \"\", -1e9\n","    score = float(out.start_logits[0, start] + out.end_logits[0, end])\n","    ans = qa_tok.decode(inputs[\"input_ids\"][0][start:end+1]).replace(\" ##\", \"\")\n","    return ans.strip(), score\n","\n","def answer_question(question: str, retrieve_k=6):\n","    cands = tfidf_search(question, top_k=retrieve_k)\n","    best = {\"answer\":\"\", \"score\":-1e9, \"context\":\"\", \"rank\":None}\n","    for rank, (ctx, sim, idx) in enumerate(cands, start=1):\n","        ans, s = extract_answer(question, ctx)\n","        if s > best[\"score\"] and ans:\n","            best.update({\"answer\": ans, \"score\": s, \"context\": ctx, \"rank\": rank})\n","    return best"]},{"cell_type":"markdown","id":"208cf3e8","metadata":{"id":"208cf3e8"},"source":["## 7) Testes para verificar se o modelo funciona"]},{"cell_type":"code","execution_count":null,"id":"134ad777","metadata":{"id":"134ad777","executionInfo":{"status":"ok","timestamp":1758316508150,"user_tz":-120,"elapsed":10162,"user":{"displayName":"KAYKY FIDELIS SERAFIM","userId":"03357177986102336329"}},"outputId":"47835ccd-12a9-4e04-a3aa-4a60efd04eb1","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': 'a group of one or more containers, with shared storage and network resources, and a specification for how to run the containers',\n"," 'score': 10.744248390197754,\n"," 'context': 'CHUNK === suggest an improvement . Last modified July 12, 2023 at 1:25 AM PST: Revise docs home page (9520b96a61) Edit this page Create child page Create an issue Print entire section === DOC CHUNK === Pods | Kubernetes # Pods Pods Pods are the smallest deployable units of computing that you can create and manage in Kubernetes. A Pod (as in a pod of whales or pea pod) is a group of one or more containers , with shared storage and network resources, and a specification for how to run the containers. A Pod\\'s contents are always co-located and co-scheduled, and run in a shared context. A Pod models an application-specific \"logical host\": it contains one or more application containers which are relatively tightly coupled. In non-cloud contexts, applications executed on the same physical or virtual machine are analogous to cloud applications executed on the same logical host. As well as application containers, a Pod can contain init containers that run during Pod startup. You can also inject ephemeral containers for debugging a running Pod. ## What is a Pod? What is a Pod? #### Note: Note: You need to install a container runtime into each node in the cluster so that Pods can run there. The shared context of a Pod is a set of Linux namespaces, cgroups, and potentially other facets of isolation - the same things that isolate a container . Within a Pod\\'s context, the individual applications may have further sub-isolations applied. A Pod is similar to a set of containers === DOC CHUNK === ## What is a Pod? What is a Pod? #### Note: Note: You need to install a container runtime into each node in the cluster so that Pods can run there. The shared context of a Pod is a set of Linux namespaces, cgroups, and potentially other facets of isolation - the same things that isolate a container . Within',\n"," 'rank': 1}"]},"metadata":{},"execution_count":23}],"source":["res = answer_question(\"What is a Pod?\")\n","res\n"]},{"cell_type":"code","source":["res = answer_question(\"What is a Cluster?\")\n","res\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XrIQ1NMOWmam","executionInfo":{"status":"ok","timestamp":1758316518663,"user_tz":-120,"elapsed":10514,"user":{"displayName":"KAYKY FIDELIS SERAFIM","userId":"03357177986102336329"}},"outputId":"59dc7a37-6d77-4a74-806a-8644a2f034ba"},"id":"XrIQ1NMOWmam","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': '[CLS]',\n"," 'score': 12.867141723632812,\n"," 'context': \"ClusterIP allocation Service ClusterIP allocation In Kubernetes, Services are an abstract way to expose an application running on a set of Pods. Services can have a cluster-scoped virtual IP address (using a Service of type: ClusterIP ). Clients can connect using that virtual IP address, and Kubernetes then load-balances traffic to that Service across the different backing Pods. ## How Service ClusterIPs are allocated? How Service ClusterIPs are allocated? When Kubernetes needs to assign a virtual IP address for a Service, that assignment happens one of two ways: dynamically the cluster's control plane automatically picks a free IP address from within the configured IP range for type: ClusterIP Services. statically you specify an IP address of your choice, from within the configured IP range for Services. Across your whole cluster, every Service ClusterIP must be unique. Trying to create a Service with a specific ClusterIP that has already been allocated will return an error. ## Why do you need to reserve Service Cluster IPs? Why do you need to reserve Service Cluster IPs? Sometimes you may want to have Services running in well-known IP addresses, so other components and users in the cluster can use them. The best example is the DNS Service for the cluster. As a soft convention, some Kubernetes installers === DOC CHUNK === must be unique. Trying to create a Service with a specific ClusterIP that has already been allocated will return an error. ## Why do you need to reserve Service Cluster IPs? Why do you need to reserve Service Cluster IPs? Sometimes you may want to have Services running in well-known IP addresses, so other components and users in the cluster can use them. The best example is the DNS Service for the cluster. As a soft convention, some Kubernetes installers assign the 10th IP address from the Service IP range to the DNS service. Assuming you configured your cluster with Service IP range\",\n"," 'rank': 5}"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["res = answer_question(\"What is Kubernetes?\")\n","res\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EC1crt6_WovR","executionInfo":{"status":"ok","timestamp":1758316528407,"user_tz":-120,"elapsed":9743,"user":{"displayName":"KAYKY FIDELIS SERAFIM","userId":"03357177986102336329"}},"outputId":"20306f15-4bde-4001-88bf-9005315f6750"},"id":"EC1crt6_WovR","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': 'open source container orchestration engine',\n"," 'score': 15.701431274414062,\n"," 'context': 'run the database in one StatefulSet and the web server in a Deployment . ## Feedback Feedback Was this page helpful? Yes No Thanks for the feedback. If you have a specific, answerable question about how to use Kubernetes, ask it on Stack Overflow . Open an issue in the GitHub Repository if you want to report a problem or suggest an improvement . Last modified April 20, 2024 at 7:09 PM PST: Ready glossary page for vanilla Docsy (2f3602cef0) Edit this page Create child page Create an issue Print entire section === DOC CHUNK === a problem or suggest an improvement . Last modified April 20, 2024 at 7:09 PM PST: Ready glossary page for vanilla Docsy (2f3602cef0) Edit this page Create child page Create an issue Print entire section === DOC CHUNK === Kubernetes Documentation | Kubernetes Kubernetes is an open source container orchestration engine for automating deployment, scaling, and management of containerized applications. The open source project is hosted by the Cloud Native Computing Foundation ( CNCF ). ## Understand Kubernetes Understand Kubernetes Learn about Kubernetes and its fundamental concepts. Why Kubernetes? Components of a cluster The Kubernetes API Objects In Kubernetes Containers Workloads and Pods View Concepts ## Try Kubernetes Try Kubernetes Follow tutorials to learn how to deploy applications in Kubernetes. Hello Minikube Walkthrough the basics Stateless Example: PHP Guestbook with Redis Stateful Example: Wordpress with Persistent Volumes View Tutorials ## Set up a K8s cluster Set up a K8s cluster Get Kubernetes running based on your resources and needs. Learning environment Production environment Install the kubeadm setup tool Securing a cluster kubeadm command reference Set up Kubernetes ## Learn how to use Kubernetes Learn how to use Kubernetes Look up common tasks and how to perform them using a short sequence of steps. kubectl Quick Reference Install kubectl Configure access to clusters Use the Web UI Dashboard Configure a Pod to Use a ConfigMap',\n"," 'rank': 1}"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["# Resultados\n","*   **Recuperação com TF-IDF: usei TF-IDF (conceito clássico visto na disciplina) para buscar os trechos mais relevantes do corpus de Kubernetes.**\n","\n","*   **Leitor com BERT: apliquei um BERT pré-treinado (SQuAD2) como leitor extractive QA para extrair a resposta do trecho recuperado.**\n","\n","*   **Pipeline funcional: perguntas comuns (Pods, Node, Cluster) retornaram respostas curtas e corretas.**\n","\n","*   **Aplicação, na prática, TF-IDF e BERT ensinados em aula para construir um sistema de perguntas e respostas sobre Kubernetes.**"],"metadata":{"id":"iYYLnsFsX02a"},"id":"iYYLnsFsX02a"}],"metadata":{"colab":{"provenance":[{"file_id":"1ExtNp8XMjPDNr7Sd8pXZlJslwYAJ8hOQ","timestamp":1758300204732}],"gpuType":"T4"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}